{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.030326,
     "end_time": "2021-01-10T14:30:49.487331",
     "exception": false,
     "start_time": "2021-01-10T14:30:49.457005",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "###### * Base Source: \n",
    "SAKT with Randomization & State Updates LB0.771 https://www.kaggle.com/leadbest/sakt-with-randomization-state-updates\n",
    "\n",
    "1. Version 1: ++bundle_id-Embedding, ++tags-Embedding,  ++CustomTrainer\n",
    "2. this is a repeat of version 8 of the notebook since at submission time I got this message:\n",
    "\"Cannot submit\n",
    "Your Notebook cannot use internet access in this competition. Please disable internet in the Notebook editor and save a new version.\"\n",
    "3. Hence, I am reusing the model trained at version 8 (rishi-sakt-featureembeddings-riidchallenge/SAKT_Rishi.pt). To get the original version 8 from this verson, remove the code: \"model.load_state_dict...\" and set the \"num_train_epochs=13\" in the first trainin loop. Second training loop still be \"num_train_epochs=1\" only.\n",
    "4. The original version runs for 8 hrs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T14:30:49.555879Z",
     "iopub.status.busy": "2021-01-10T14:30:49.555015Z",
     "iopub.status.idle": "2021-01-10T14:30:49.566320Z",
     "shell.execute_reply": "2021-01-10T14:30:49.565745Z"
    },
    "papermill": {
     "duration": 0.050166,
     "end_time": "2021-01-10T14:30:49.566421",
     "exception": false,
     "start_time": "2021-01-10T14:30:49.516255",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/rishi-sakt-featureembeddings-riidchallenge/SAKT_Rishi.pt\n",
      "/kaggle/input/riiid-test-answer-prediction/example_sample_submission.csv\n",
      "/kaggle/input/riiid-test-answer-prediction/example_test.csv\n",
      "/kaggle/input/riiid-test-answer-prediction/questions.csv\n",
      "/kaggle/input/riiid-test-answer-prediction/train.csv\n",
      "/kaggle/input/riiid-test-answer-prediction/lectures.csv\n",
      "/kaggle/input/riiid-test-answer-prediction/riiideducation/competition.cpython-37m-x86_64-linux-gnu.so\n",
      "/kaggle/input/riiid-test-answer-prediction/riiideducation/__init__.py\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2021-01-10T14:30:49.633665Z",
     "iopub.status.busy": "2021-01-10T14:30:49.633064Z",
     "iopub.status.idle": "2021-01-10T14:30:59.687267Z",
     "shell.execute_reply": "2021-01-10T14:30:59.686062Z"
    },
    "papermill": {
     "duration": 10.091698,
     "end_time": "2021-01-10T14:30:59.687390",
     "exception": false,
     "start_time": "2021-01-10T14:30:49.595692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gc\n",
    "import random\n",
    "from   tqdm import tqdm\n",
    "from   sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import psutil\n",
    "import datatable as dt\n",
    "from collections import namedtuple  \n",
    "\n",
    "import os\n",
    "import seaborn as sns\n",
    "from   sklearn.utils import shuffle\n",
    "import datetime\n",
    "import time\n",
    "from   sklearn.metrics import accuracy_score, precision_recall_fscore_support, matthews_corrcoef, roc_auc_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "from   torch.autograd import Variable\n",
    "from   torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from   transformers import TrainingArguments\n",
    "from   transformers import AdamW, BertConfig\n",
    "from   transformers import get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T14:30:59.753374Z",
     "iopub.status.busy": "2021-01-10T14:30:59.751683Z",
     "iopub.status.idle": "2021-01-10T14:30:59.754120Z",
     "shell.execute_reply": "2021-01-10T14:30:59.754623Z"
    },
    "papermill": {
     "duration": 0.036008,
     "end_time": "2021-01-10T14:30:59.754743",
     "exception": false,
     "start_time": "2021-01-10T14:30:59.718735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_SEQ = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.030969,
     "end_time": "2021-01-10T14:30:59.814152",
     "exception": false,
     "start_time": "2021-01-10T14:30:59.783183",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load train df and join the tags column from the questions df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T14:30:59.890499Z",
     "iopub.status.busy": "2021-01-10T14:30:59.889599Z",
     "iopub.status.idle": "2021-01-10T14:32:57.500382Z",
     "shell.execute_reply": "2021-01-10T14:32:57.499838Z"
    },
    "papermill": {
     "duration": 117.655737,
     "end_time": "2021-01-10T14:32:57.500502",
     "exception": false,
     "start_time": "2021-01-10T14:30:59.844765",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 9s, sys: 4.94 s, total: 1min 14s\n",
      "Wall time: 1min 57s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>content_type_id</th>\n",
       "      <th>answered_correctly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>5692</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56943</td>\n",
       "      <td>115</td>\n",
       "      <td>5716</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>118363</td>\n",
       "      <td>115</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>131167</td>\n",
       "      <td>115</td>\n",
       "      <td>7860</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>137965</td>\n",
       "      <td>115</td>\n",
       "      <td>7922</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  user_id  content_id  content_type_id  answered_correctly\n",
       "0          0      115        5692                0                   1\n",
       "1      56943      115        5716                0                   1\n",
       "2     118363      115         128                0                   1\n",
       "3     131167      115        7860                0                   1\n",
       "4     137965      115        7922                0                   1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "dtype = {'timestamp'         :'int64', \n",
    "         'user_id'           :'int32' ,\n",
    "         'content_id'        :'int16',\n",
    "         'content_type_id'   :'int8',\n",
    "         'answered_correctly':'int8'}\n",
    "\n",
    "train_df = pd.read_csv ('../input/riiid-test-answer-prediction/train.csv', usecols=[1, 2, 3, 4, 7], dtype=dtype)\n",
    "# train_df = train_df.sample (frac=0.0001)  # TODO: comment this\n",
    "train_df.head ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T14:32:57.571336Z",
     "iopub.status.busy": "2021-01-10T14:32:57.570771Z",
     "iopub.status.idle": "2021-01-10T14:32:57.638869Z",
     "shell.execute_reply": "2021-01-10T14:32:57.639374Z"
    },
    "papermill": {
     "duration": 0.108678,
     "end_time": "2021-01-10T14:32:57.639492",
     "exception": false,
     "start_time": "2021-01-10T14:32:57.530814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>bundle_id</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[51, 131, 162, 38, 51]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[131, 36, 81, 131, 36]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[131, 101, 162, 92, 131]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[131, 149, 162, 29, 131]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[131, 5, 162, 38, 131]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_id  bundle_id                      tags\n",
       "0            0          0    [51, 131, 162, 38, 51]\n",
       "1            1          1    [131, 36, 81, 131, 36]\n",
       "2            2          2  [131, 101, 162, 92, 131]\n",
       "3            3          3  [131, 149, 162, 29, 131]\n",
       "4            4          4    [131, 5, 162, 38, 131]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtype = {\n",
    "    'question_id' :'int16',\n",
    "    'bundle_id'   :'int16', \n",
    "    'tags'        :'str',\n",
    "}\n",
    "questions_df         = pd.read_csv ('../input/riiid-test-answer-prediction/questions.csv', usecols=[0, 1, 4], dtype=dtype)\n",
    "# convert tag from string and pad the tags with 0 and make it as fixed length (=5) array\n",
    "questions_df['tags'] = questions_df['tags'].map (lambda s: [int(v) for v in s.split()], 'ignore')\n",
    "questions_df['tags'] = questions_df['tags'].fillna (0)\n",
    "questions_df['tags'] = questions_df['tags'].map (lambda s: [0]*5 if s==0 else s*(5//len(s))+s[:5%len(s)] if len(s)<5 else s[:5] )\n",
    "questions_df.head ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T14:32:57.706764Z",
     "iopub.status.busy": "2021-01-10T14:32:57.706163Z",
     "iopub.status.idle": "2021-01-10T14:33:24.474385Z",
     "shell.execute_reply": "2021-01-10T14:33:24.473232Z"
    },
    "papermill": {
     "duration": 26.803288,
     "end_time": "2021-01-10T14:33:24.474570",
     "exception": false,
     "start_time": "2021-01-10T14:32:57.671282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = train_df[train_df.content_type_id == False]\n",
    "#arrange by timestamp\n",
    "train_df = train_df.sort_values (['timestamp'], ascending=True).reset_index (drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.030544,
     "end_time": "2021-01-10T14:33:24.536157",
     "exception": false,
     "start_time": "2021-01-10T14:33:24.505613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.030475,
     "end_time": "2021-01-10T14:33:24.596994",
     "exception": false,
     "start_time": "2021-01-10T14:33:24.566519",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T14:33:24.666408Z",
     "iopub.status.busy": "2021-01-10T14:33:24.665343Z",
     "iopub.status.idle": "2021-01-10T14:33:24.675614Z",
     "shell.execute_reply": "2021-01-10T14:33:24.676250Z"
    },
    "papermill": {
     "duration": 0.049197,
     "end_time": "2021-01-10T14:33:24.676409",
     "exception": false,
     "start_time": "2021-01-10T14:33:24.627212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number bundles = 9765\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13523"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "known_bundle_ids = set (questions_df[\"bundle_id\"].unique())\n",
    "print(\"number bundles =\", len (known_bundle_ids))\n",
    "n_bundles = max (known_bundle_ids) + 1\n",
    "n_bundles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T14:33:24.744736Z",
     "iopub.status.busy": "2021-01-10T14:33:24.743418Z",
     "iopub.status.idle": "2021-01-10T14:33:25.478379Z",
     "shell.execute_reply": "2021-01-10T14:33:25.477768Z"
    },
    "papermill": {
     "duration": 0.770731,
     "end_time": "2021-01-10T14:33:25.478488",
     "exception": false,
     "start_time": "2021-01-10T14:33:24.707757",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "skills  = train_df[\"content_id\"].unique ()\n",
    "# n_skill = max (skills) + 1\n",
    "# max (skills), len(skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T14:33:25.550147Z",
     "iopub.status.busy": "2021-01-10T14:33:25.549472Z",
     "iopub.status.idle": "2021-01-10T14:33:25.562437Z",
     "shell.execute_reply": "2021-01-10T14:33:25.561891Z"
    },
    "papermill": {
     "duration": 0.051125,
     "end_time": "2021-01-10T14:33:25.562539",
     "exception": false,
     "start_time": "2021-01-10T14:33:25.511414",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number questions = 13523\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13523"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "known_qtn_ids = set (questions_df[\"question_id\"].unique())\n",
    "print (\"number questions =\", len (known_qtn_ids))\n",
    "n_skill = max (known_qtn_ids) + 1\n",
    "n_skill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T14:33:25.648179Z",
     "iopub.status.busy": "2021-01-10T14:33:25.637770Z",
     "iopub.status.idle": "2021-01-10T14:33:29.590740Z",
     "shell.execute_reply": "2021-01-10T14:33:29.591669Z"
    },
    "papermill": {
     "duration": 3.997025,
     "end_time": "2021-01-10T14:33:29.591830",
     "exception": false,
     "start_time": "2021-01-10T14:33:25.594805",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(188, 188)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "known_tags = questions_df[\"tags\"].apply (pd.Series).unstack ().reset_index ().dropna ()\n",
    "known_tags = set (known_tags[0].astype ('int16').unique ())\n",
    "n_tags     = max (known_tags) + 1\n",
    "n_tags, len (known_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T14:33:29.841872Z",
     "iopub.status.busy": "2021-01-10T14:33:29.840647Z",
     "iopub.status.idle": "2021-01-10T14:33:29.844689Z",
     "shell.execute_reply": "2021-01-10T14:33:29.845213Z"
    },
    "papermill": {
     "duration": 0.218718,
     "end_time": "2021-01-10T14:33:29.845381",
     "exception": false,
     "start_time": "2021-01-10T14:33:29.626663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>content_type_id</th>\n",
       "      <th>answered_correctly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>5692</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1805962620</td>\n",
       "      <td>5547</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2015251289</td>\n",
       "      <td>4024</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>867941388</td>\n",
       "      <td>6659</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>867946278</td>\n",
       "      <td>3977</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp     user_id  content_id  content_type_id  answered_correctly\n",
       "0          0         115        5692                0                   1\n",
       "1          0  1805962620        5547                0                   0\n",
       "2          0  2015251289        4024                0                   1\n",
       "3          0   867941388        6659                0                   1\n",
       "4          0   867946278        3977                0                   1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_df = train_df.merge (questions_df, left_on='content_id', right_on='question_id', how='left').drop (columns=['question_id'])\n",
    "gc.collect ()\n",
    "train_df.head ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T14:33:30.400720Z",
     "iopub.status.busy": "2021-01-10T14:33:30.234729Z",
     "iopub.status.idle": "2021-01-10T14:34:06.376032Z",
     "shell.execute_reply": "2021-01-10T14:34:06.376539Z"
    },
    "papermill": {
     "duration": 36.496089,
     "end_time": "2021-01-10T14:34:06.376699",
     "exception": false,
     "start_time": "2021-01-10T14:33:29.880610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id\n",
       "115           ([5692, 5716, 128, 7860, 7922, 156, 51, 50, 78...\n",
       "124           ([7900, 7876, 175, 1278, 2065, 2063, 2064, 336...\n",
       "2746          ([5273, 758, 5976, 236, 404, 382, 405, 873, 53...\n",
       "5382          ([5000, 3944, 217, 5844, 5965, 4990, 5235, 605...\n",
       "8623          ([3915, 4750, 6456, 3968, 6104, 5738, 6435, 54...\n",
       "                                    ...                        \n",
       "2147470770    ([7900, 7876, 175, 1278, 2064, 2063, 2065, 336...\n",
       "2147470777    ([7900, 7876, 175, 1278, 2065, 2063, 2064, 336...\n",
       "2147481750    ([4137, 1270, 9261, 8201, 367, 378, 214, 6071,...\n",
       "2147482216    ([3748, 4765, 5474, 9261, 4665, 5987, 6666, 56...\n",
       "2147482888    ([6147, 4792, 5738, 6102, 4748, 7956, 6435, 92...\n",
       "Length: 393656, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To save from going out of memory, split the df into 2, then create the groups below and join them back\n",
    "train_df_1 = train_df[:train_df.shape[0]//2]\n",
    "train_df_2 = train_df[train_df.shape[0]//2:]\n",
    "del train_df; gc.collect ()                  # TODO - uncomment this\n",
    "\n",
    "group = train_df_1[['user_id', 'content_id', 'answered_correctly']].groupby('user_id').apply (lambda r: (\n",
    "            r['content_id'].values,\n",
    "            r['answered_correctly'].values,\n",
    "))\n",
    "del train_df_1\n",
    "gc.collect ()\n",
    "group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T14:34:06.773233Z",
     "iopub.status.busy": "2021-01-10T14:34:06.771214Z",
     "iopub.status.idle": "2021-01-10T14:34:21.813668Z",
     "shell.execute_reply": "2021-01-10T14:34:21.814497Z"
    },
    "papermill": {
     "duration": 15.401468,
     "end_time": "2021-01-10T14:34:21.814673",
     "exception": false,
     "start_time": "2021-01-10T14:34:06.413205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id\n",
       "12741         ([10071, 10072, 10070, 10073, 10950, 10948, 10...\n",
       "13134         ([8736, 6156, 1030, 11875, 902, 317, 1224, 120...\n",
       "24418         ([4821, 5177, 6328, 9187, 649, 207, 1181, 317,...\n",
       "40828         ([4782, 4975, 9536, 3859, 5618, 6265, 8910, 41...\n",
       "44331         ([153, 10767, 10770, 10769, 10768, 6917, 6916,...\n",
       "                                    ...                        \n",
       "2147382115    ([6058, 9171, 5544, 4821, 6121, 8561, 5631, 59...\n",
       "2147413636    ([1911, 1912, 1910, 2424, 2423, 2422, 567, 515...\n",
       "2147419988    ([7946, 10577, 185, 7908, 130, 10405, 10485, 8...\n",
       "2147470770    ([1383, 951, 1296, 1217, 749, 582, 438, 972, 8...\n",
       "2147470777    ([141, 127, 7881, 10646, 7913, 38, 25, 10651, ...\n",
       "Length: 123833, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_2 = train_df_2[['user_id', 'content_id', 'answered_correctly']].groupby('user_id').apply (lambda r: (\n",
    "            r['content_id'].values,\n",
    "            r['answered_correctly'].values,\n",
    "))\n",
    "del train_df_2\n",
    "gc.collect ()\n",
    "group_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T14:34:21.922000Z",
     "iopub.status.busy": "2021-01-10T14:34:21.920831Z",
     "iopub.status.idle": "2021-01-10T14:40:49.661881Z",
     "shell.execute_reply": "2021-01-10T14:40:49.661170Z"
    },
    "papermill": {
     "duration": 387.81171,
     "end_time": "2021-01-10T14:40:49.662014",
     "exception": false,
     "start_time": "2021-01-10T14:34:21.850304",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len (group) = 393656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "user_id\n",
       "115           ([5692, 5716, 128, 7860, 7922, 156, 51, 50, 78...\n",
       "124           ([7900, 7876, 175, 1278, 2065, 2063, 2064, 336...\n",
       "2746          ([5273, 758, 5976, 236, 404, 382, 405, 873, 53...\n",
       "5382          ([5000, 3944, 217, 5844, 5965, 4990, 5235, 605...\n",
       "8623          ([3915, 4750, 6456, 3968, 6104, 5738, 6435, 54...\n",
       "                                    ...                        \n",
       "2147470770    ([7900, 7876, 175, 1278, 2064, 2063, 2065, 336...\n",
       "2147470777    ([7900, 7876, 175, 1278, 2065, 2063, 2064, 336...\n",
       "2147481750    ([4137, 1270, 9261, 8201, 367, 378, 214, 6071,...\n",
       "2147482216    ([3748, 4765, 5474, 9261, 4665, 5987, 6666, 56...\n",
       "2147482888    ([6147, 4792, 5738, 6102, 4748, 7956, 6435, 92...\n",
       "Length: 393656, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge the groups\n",
    "group_2_set = set (group_2.index)\n",
    "for k in group.index:\n",
    "    if k in group_2_set:\n",
    "        \n",
    "        group[k] = (np.append (group[k][0],  group_2[k][0]), np.append (group[k][1],  group_2[k][1]) ) #, np.append (group[k][2],  group_2[k][2]), np.vstack ((group[k][3], group_2[k][3])) )\n",
    "        group_2.pop (k)\n",
    "gc.collect ()\n",
    "group = group.append (group_2)\n",
    "del group_2; gc.collect ()\n",
    "print ('len (group) =', len (group))\n",
    "group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T14:40:49.745753Z",
     "iopub.status.busy": "2021-01-10T14:40:49.744934Z",
     "iopub.status.idle": "2021-01-10T14:40:49.749904Z",
     "shell.execute_reply": "2021-01-10T14:40:49.749331Z"
    },
    "papermill": {
     "duration": 0.046734,
     "end_time": "2021-01-10T14:40:49.750021",
     "exception": false,
     "start_time": "2021-01-10T14:40:49.703287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "random.seed (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T14:40:49.936696Z",
     "iopub.status.busy": "2021-01-10T14:40:49.922016Z",
     "iopub.status.idle": "2021-01-10T14:40:49.989782Z",
     "shell.execute_reply": "2021-01-10T14:40:49.991032Z"
    },
    "papermill": {
     "duration": 0.204348,
     "end_time": "2021-01-10T14:40:49.991240",
     "exception": false,
     "start_time": "2021-01-10T14:40:49.786892",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SAKTDataset (Dataset):\n",
    "    \n",
    "    def __init__(self, group, n_skill, max_seq=MAX_SEQ):\n",
    "        \n",
    "        super (SAKTDataset, self).__init__()\n",
    "        self.max_seq   = max_seq\n",
    "        self.n_skill   = n_skill\n",
    "        self.n_bundles = n_bundles\n",
    "        self.n_tags    = n_tags\n",
    "        self.samples   = group\n",
    "        \n",
    "        # self.user_ids = [x for x in group.index]\n",
    "        self.user_ids  = []\n",
    "        for user_id in group.index:\n",
    "            \n",
    "            # q, qa, b, t = group[user_id]\n",
    "            q, qa = group[user_id]\n",
    "            if len(q) < 2: #  10\n",
    "                continue\n",
    "            self.user_ids.append (user_id)\n",
    "            \n",
    "            # Memory reduction\n",
    "            # if len(q)>self.max_seq:\n",
    "            #     group[user_id] = (q[-self.max_seq:],qa[-self.max_seq:])\n",
    "        return\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.user_ids)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        user_id  = self.user_ids[index]\n",
    "        # q_, qa_, b_, t_ = self.samples[user_id]\n",
    "        q_, qa_  = self.samples[user_id]\n",
    "        q_b_t_df = pd.DataFrame.from_dict ({'question_id': q_})\n",
    "        q_b_t_df = q_b_t_df.merge (questions_df, on='question_id', how='left')\n",
    "        b_       = q_b_t_df.bundle_id.values\n",
    "        t_       = np.vstack (q_b_t_df.tags.values)\n",
    "        del q_b_t_df\n",
    "        seq_len  = len (q_)\n",
    "        \n",
    "        q  = np.zeros (self.max_seq, dtype=int)\n",
    "        qa = np.zeros (self.max_seq, dtype=int)\n",
    "        b  = np.zeros (self.max_seq, dtype=int)\n",
    "        t  = np.array ([[0]*5]*self.max_seq, dtype=int)  # a question can have upto say 5 tags\n",
    "        \n",
    "        if seq_len >= self.max_seq:\n",
    "            if random.random ()>0.1:\n",
    "                \n",
    "                start = random.randint (0,(seq_len-self.max_seq))\n",
    "                end   = start + self.max_seq\n",
    "                q[:]  = q_[start:end]\n",
    "                qa[:] = qa_[start:end]\n",
    "                b[:]  = b_[start:end]\n",
    "                t[:]  = t_[start:end]\n",
    "            else:\n",
    "                \n",
    "                q[:]  = q_[-self.max_seq:]\n",
    "                qa[:] = qa_[-self.max_seq:]\n",
    "                b[:]  = b_[-self.max_seq:]\n",
    "                t[:]  = t_[-self.max_seq:]\n",
    "        else:\n",
    "            if random.random ()>0.1:\n",
    "                \n",
    "                start = 0\n",
    "                end = random.randint (2,seq_len)\n",
    "                seq_len = end - start\n",
    "                q[-seq_len:]  = q_[0:seq_len]\n",
    "                qa[-seq_len:] = qa_[0:seq_len]\n",
    "                b[-seq_len:]  = b_[0:seq_len]\n",
    "                t[-seq_len:]  = t_[0:seq_len]\n",
    "            else:\n",
    "                \n",
    "                q[-seq_len:]  = q_\n",
    "                qa[-seq_len:] = qa_\n",
    "                b[-seq_len:]  = b_\n",
    "                t[-seq_len:]  = t_\n",
    "        target_id = q[1:]\n",
    "        label = qa[1:]\n",
    "\n",
    "        x = np.zeros (self.max_seq-1, dtype=int)\n",
    "        x = q[:-1].copy ()\n",
    "        x += (qa[:-1] == 1) * self.n_skill\n",
    "        \n",
    "        bundle_x = b[:-1].copy ()\n",
    "        tags_x   = t[:-1].copy ()\n",
    "        b_target = b[1:]\n",
    "        t_target = t[1:]\n",
    "        \n",
    "        return x, target_id, label, bundle_x, tags_x, b_target, t_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.058425,
     "end_time": "2021-01-10T14:40:50.109476",
     "exception": false,
     "start_time": "2021-01-10T14:40:50.051051",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T14:40:50.238494Z",
     "iopub.status.busy": "2021-01-10T14:40:50.237411Z",
     "iopub.status.idle": "2021-01-10T14:40:50.275462Z",
     "shell.execute_reply": "2021-01-10T14:40:50.276706Z"
    },
    "papermill": {
     "duration": 0.107487,
     "end_time": "2021-01-10T14:40:50.276912",
     "exception": false,
     "start_time": "2021-01-10T14:40:50.169425",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FFN (nn.Module):\n",
    "    \n",
    "    def __init__(self, state_size=200):\n",
    "        super (FFN, self).__init__()\n",
    "        self.state_size = state_size\n",
    "\n",
    "        self.lr1 = nn.Linear (state_size, state_size)\n",
    "        self.relu = nn.ReLU ()\n",
    "        self.lr2 = nn.Linear (state_size, state_size)\n",
    "        self.dropout = nn.Dropout (0.2)\n",
    "    \n",
    "    def forward (self, x):\n",
    "        x = self.lr1 (x)\n",
    "        x = self.relu (x)\n",
    "        x = self.lr2 (x)\n",
    "        return self.dropout (x)\n",
    "\n",
    "def future_mask (seq_length):\n",
    "    future_mask = np.triu (np.ones ((seq_length, seq_length)), k=1).astype ('bool')\n",
    "    return torch.from_numpy (future_mask)\n",
    "\n",
    "\n",
    "class SAKTModel (nn.Module):\n",
    "    \n",
    "    def __init__(self, n_skill, max_seq=MAX_SEQ, embed_dim=128): #  100->MAX_SEQ\n",
    "        super(SAKTModel, self).__init__()\n",
    "        self.n_skill   = n_skill\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "        self.embedding        = nn.Embedding (2*n_skill+1, embed_dim)\n",
    "        self.pos_embedding    = nn.Embedding (max_seq-1,   embed_dim)\n",
    "        self.e_embedding      = nn.Embedding (n_skill+1,   embed_dim)\n",
    "        self.bundle_embedding = nn.Embedding (n_bundles,   embed_dim)\n",
    "        self.tag_embedding    = nn.Embedding (n_tags,      embed_dim)\n",
    "\n",
    "        self.multi_att    = nn.MultiheadAttention (embed_dim=embed_dim, num_heads=8, dropout=0.2)\n",
    "\n",
    "        self.dropout      = nn.Dropout (0.2)\n",
    "        self.layer_normal = nn.LayerNorm (embed_dim) \n",
    "        self.ffn          = FFN (embed_dim)\n",
    "        self.outDense     = nn.Linear (embed_dim, 2)\n",
    "        self.outActivtn   = nn.LogSoftmax (dim=1)\n",
    "        self.NLLLoss      = nn.NLLLoss ()             # criterion\n",
    "        return\n",
    "    \n",
    "    def getTagsEmb (self, tags):\n",
    "        \"\"\"\n",
    "        list_of_tagList 3D np.array of size (1, seqLen, 5) \n",
    "        \"\"\"\n",
    "        \n",
    "        t_emb = self.tag_embedding (tags)\n",
    "        t_emb = torch.mean (t_emb, dim=-2)\n",
    "        return t_emb\n",
    "        \n",
    "    def forward (self, x, question_ids, bundle_x, tags_x, b_target, t_target, labels=None):\n",
    "        \"\"\"\n",
    "        when you call `model (x ,y, z, ...)` then thid method is invoked\n",
    "        \"\"\"\n",
    "        \n",
    "        device   = x.device                                            #;print ('x.shape        =', x.shape)\n",
    "        x        = self.embedding (x)                                  #;print ('x.shape        =', x.shape)\n",
    "        pos_id   = torch.arange (x.size (1)).unsqueeze (0).to (device) #;print ('pos_id.shape   =', pos_id.shape)\n",
    "        pos_x    = self.pos_embedding (pos_id)                         #;print ('pos_x.shape    =', pos_x.shape)\n",
    "        bundle_x = self.bundle_embedding (bundle_x)                    #;print ('bundle_x.shape =', bundle_x.shape)\n",
    "        b_target = self.bundle_embedding (b_target)                    #;print ('b_target.shape =', b_target.shape)\n",
    "        tags_x   = self.getTagsEmb (tags_x)                            #;print ('tags_x.shape   =', tags_x.shape)\n",
    "        t_target = self.getTagsEmb (t_target)                          #;print ('t_target.shape =', t_target.shape)\n",
    "        \n",
    "        # x    = x + pos_x\n",
    "        x      = x + pos_x + bundle_x + tags_x                         #;print ('x.shape        =', x.shape) \n",
    "        # e    = self.e_embedding (question_ids)\n",
    "        e      = self.e_embedding (question_ids) + b_target + t_target #;print ('e.shape        =', e.shape)\n",
    "        \n",
    "        x = x.permute (1, 0, 2) ;\"\"\"x: [bs, s_len, embed] => [s_len, bs, embed]\"\"\"   #;print ('x.shape        =', x.shape)\n",
    "        e = e.permute (1, 0, 2)                                        #;print ('e.shape        =', e.shape)\n",
    "        att_mask   = future_mask (x.size (0)).to (device)              #;print ('att_mask.shape = ', att_mask.shape) \n",
    "        att_output, att_weight = self.multi_att (e, x, x, attn_mask=att_mask)   #;print ('att_output.shape = ', att_output.shape) \n",
    "        att_output = self.layer_normal (att_output + e)                #;print ('att_output.shape = ', att_output.shape) \n",
    "        att_output = att_output.permute (1, 0, 2) #;\"\"\"att_output: [s_len, bs, embed] => [bs, s_len, embed]\"\"\" ;print ('att_output.shape = ', att_output.shape) \n",
    "\n",
    "        x          = self.ffn (att_output)                             #;print ('x.shape = ', x.shape) \n",
    "        x          = self.layer_normal (x + att_output)                #;print ('x.shape = ', x.shape) \n",
    "        out_logits = self.outDense (x)                                 #;print ('out_logits.shape = ', out_logits.shape)        \n",
    "        \n",
    "        if labels is None:\n",
    "            \n",
    "            # target question id is the last in the sequence of target question ids, hence return the last col\n",
    "            out_logits = out_logits[:, -1]\n",
    "            # return a named tuple\n",
    "            Logits     = namedtuple ('Logits',['logits'])\n",
    "            out_logits = Logits (out_logits)\n",
    "            return out_logits\n",
    "        \n",
    "        out_logits = out_logits.view (out_logits.shape[0] * out_logits.shape[1], -1)           #;print ('out_logits.shape = ', out_logits.shape)\n",
    "        log_ps     = self.outActivtn (out_logits)                                              # ;print('labels.size=', labels.size(), 'log_ps.size=', log_ps.size())\n",
    "        labels     = torch.squeeze (labels.view (labels.shape[0] * labels.shape[1], -1), -1)   # ;print ('labels.shape = ', labels.shape)\n",
    "        batchLoss  = self.NLLLoss (log_ps, labels)\n",
    "        \n",
    "        # return a named tuple\n",
    "        Loss_Logits = namedtuple ('Loss_Logits',['loss','logits'])\n",
    "        loss_logits = Loss_Logits (batchLoss, out_logits)\n",
    "        return loss_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.054729,
     "end_time": "2021-01-10T14:40:50.387500",
     "exception": false,
     "start_time": "2021-01-10T14:40:50.332771",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create Train and Eval Datasets and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T14:40:50.602658Z",
     "iopub.status.busy": "2021-01-10T14:40:50.601647Z",
     "iopub.status.idle": "2021-01-10T14:40:51.387561Z",
     "shell.execute_reply": "2021-01-10T14:40:51.386975Z"
    },
    "papermill": {
     "duration": 0.943328,
     "end_time": "2021-01-10T14:40:51.387667",
     "exception": false,
     "start_time": "2021-01-10T14:40:50.444339",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len (train_group) = 373974\n",
      "len (eval_group) = 19682\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "user_id\n",
       "2058553426    ([7900, 7876, 175, 1278, 2064, 2065, 2063, 336...\n",
       "1658799651    ([7900, 7876, 175, 1278, 2065, 2064, 2063, 336...\n",
       "564422495     ([7900, 7876, 175, 1278, 2065, 2063, 2064, 336...\n",
       "1744078086    ([3560, 8275, 98, 6374, 5070, 5651, 5338, 5673...\n",
       "1980281378    ([7900, 7876, 175, 1278, 2064, 2063, 2065, 336...\n",
       "                                    ...                        \n",
       "1726635395    ([4303, 1328, 367, 5613, 3577, 4536, 8503, 448...\n",
       "399439114     ([3817, 5564, 1294, 4058, 5182, 98, 4934, 5624...\n",
       "203070452     ([7900, 7876, 175, 1278, 2063, 2065, 2064, 336...\n",
       "758084219     ([7900, 7876, 175, 1278, 2064, 2065, 2063, 336...\n",
       "746969510     ([6258, 4841, 9557, 8358, 8388, 4511, 3939, 49...\n",
       "Length: 373974, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frac  = 0.05\n",
    "temp  = list (group.index)\n",
    "temp  = shuffle (temp)\n",
    "frac  = int (len (temp) * frac)\n",
    "temp2 = temp[:frac]\n",
    "temp  = temp[frac:]\n",
    "train_group = group[temp]\n",
    "eval_group  = group[temp2]\n",
    "del group\n",
    "gc.collect ()\n",
    "print ('len (train_group) =', len (train_group))\n",
    "print ('len (eval_group) =',  len (eval_group))\n",
    "train_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T14:40:51.473887Z",
     "iopub.status.busy": "2021-01-10T14:40:51.473043Z",
     "iopub.status.idle": "2021-01-10T14:40:55.102342Z",
     "shell.execute_reply": "2021-01-10T14:40:55.103004Z"
    },
    "papermill": {
     "duration": 3.677862,
     "end_time": "2021-01-10T14:40:55.103188",
     "exception": false,
     "start_time": "2021-01-10T14:40:51.425326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(255,) (255,) (255,) (255,) (255, 5) (255,) (255, 5)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SAKTDataset (train_group, n_skill)\n",
    "eval_dataset  = SAKTDataset (eval_group,  n_skill)\n",
    "print (train_dataset[1][0].shape, train_dataset[1][1].shape, train_dataset[1][2].shape, train_dataset[1][3].shape, train_dataset[1][4].shape, train_dataset[1][5].shape, train_dataset[1][6].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T14:40:55.206915Z",
     "iopub.status.busy": "2021-01-10T14:40:55.205995Z",
     "iopub.status.idle": "2021-01-10T14:40:55.209653Z",
     "shell.execute_reply": "2021-01-10T14:40:55.209123Z"
    },
    "papermill": {
     "duration": 0.065135,
     "end_time": "2021-01-10T14:40:55.209754",
     "exception": false,
     "start_time": "2021-01-10T14:40:55.144619",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Utilities for my custom trainer\n",
    "\n",
    "def format_time (elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    \n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str (datetime.timedelta (seconds=elapsed_rounded))\n",
    "\n",
    "def compute_metrics (labels, pred_logits):\n",
    "    \n",
    "    preds   = pred_logits.argmax (-1)             #;print ('labels.shape=', labels.shape, 'preds.shape=', preds.shape, 'pred_logits.shape=', pred_logits.shape)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support (labels, preds, average='macro')\n",
    "    acc     = accuracy_score (labels, preds)\n",
    "    mcc     = matthews_corrcoef (labels, preds)   # matthews correlation coefficient\n",
    "    softmax = nn.Softmax (dim=1)\n",
    "    pred_pr = softmax (torch.tensor (pred_logits))\n",
    "    auc     = roc_auc_score (labels, pred_pr[:, 1])\n",
    "    metrics = {\n",
    "        'mcc'      : mcc,\n",
    "        'accuracy' : acc,\n",
    "        'f1'       : f1,\n",
    "        'precision': precision,\n",
    "        'recall'   : recall,\n",
    "        'auc'      : auc\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T14:40:55.326659Z",
     "iopub.status.busy": "2021-01-10T14:40:55.301427Z",
     "iopub.status.idle": "2021-01-10T14:40:55.396765Z",
     "shell.execute_reply": "2021-01-10T14:40:55.396106Z"
    },
    "papermill": {
     "duration": 0.148775,
     "end_time": "2021-01-10T14:40:55.396883",
     "exception": false,
     "start_time": "2021-01-10T14:40:55.248108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MyTrainer:\n",
    "    \n",
    "    def __init__(self, model, args, train_dataset, eval_dataset, compute_metrics=compute_metrics):\n",
    "        \n",
    "        self.model           = model\n",
    "        self.args            = args\n",
    "        self.train_dataset   = train_dataset\n",
    "        self.eval_dataset    = eval_dataset\n",
    "        self.compute_metrics = compute_metrics\n",
    "        self.isTrained       = False\n",
    "        self.device          = self.get_device_type ()\n",
    "        \n",
    "        # Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
    "        # I believe the 'W' stands for 'Weight Decay fix\"\n",
    "        self.optimizer = AdamW (model.parameters (),\n",
    "                           lr  = args.learning_rate,\n",
    "                           eps = args.adam_epsilon # args.adam_epsilon  - default is 1e-8 is â€œa very small number to prevent any division by zero\"\n",
    "        )\n",
    "\n",
    "        # Number of training epochs. The BERT authors recommend between 2 and 4. \n",
    "        # We chose to run for 4, but we'll see later that this may be over-fitting the\n",
    "        # training data.\n",
    "        self.epochs = self.args.num_train_epochs\n",
    "        self.train_dataloader, self.validation_dataloader, self.lr_scheduler, self.num_training_steps = self.get_dataLoaders ()        \n",
    "        return\n",
    "    \n",
    "    def get_device_type (self):\n",
    "        \n",
    "        # If there's a GPU available...\n",
    "        if torch.cuda.is_available ():    \n",
    "\n",
    "            # Tell PyTorch to use the GPU.    \n",
    "            device = torch.device (\"cuda\")\n",
    "            print('There are %d GPU(s) available.' % torch.cuda.device_count ())\n",
    "            print('We will use the GPU:', torch.cuda.get_device_name (0))\n",
    "        # If not...\n",
    "        else:\n",
    "            print('No GPU available, using the CPU instead.')\n",
    "            device = torch.device (\"cpu\")\n",
    "        return device\n",
    "    \n",
    "    def get_dataLoaders (self):        \n",
    "        \n",
    "        # Create the DataLoaders for our training and validation sets.\n",
    "        if isinstance (self.train_dataset, torch.utils.data.IterableDataset):\n",
    "            train_sampler = None\n",
    "        else:\n",
    "            train_sampler = SequentialSampler (self.train_dataset)       # Better use RandomSampler\n",
    "        train_dataloader  = DataLoader (\n",
    "                    self.train_dataset,                                  # The training samples.\n",
    "                    sampler     = train_sampler,                           \n",
    "                    batch_size  = self.args.per_device_train_batch_size,\n",
    "                    num_workers = 8    # TODO: uncomment this\n",
    "        )\n",
    "        validation_dataloader = None\n",
    "        if self.eval_dataset:\n",
    "            \n",
    "            # For validation the order doesn't matter, so we'll just read them sequentially.\n",
    "            validation_dataloader = DataLoader (\n",
    "                        self.eval_dataset,             # The validation/dev samples.\n",
    "                        sampler     = SequentialSampler (self.eval_dataset),\n",
    "                        batch_size  = self.args.per_device_eval_batch_size,\n",
    "                        num_workers = 8    # TODO: uncomment this\n",
    "            )\n",
    "        \n",
    "        # Total number of training steps is [number of batches] x [number of epochs]. \n",
    "        # (Note that this is not the same as the number of training samples).\n",
    "        num_training_steps = len (train_dataloader) * self.epochs\n",
    "\n",
    "        # Create the learning rate scheduler.\n",
    "        lr_scheduler = get_linear_schedule_with_warmup (self.optimizer, \n",
    "                                                        num_warmup_steps   = self.args.warmup_steps, # Default value in run_glue.py\n",
    "                                                        num_training_steps = num_training_steps)\n",
    "        return train_dataloader, validation_dataloader, lr_scheduler, num_training_steps\n",
    "    \n",
    "    \n",
    "    def test_iterate_dataloader ():\n",
    "        \n",
    "        for step, batch in enumerate (self.train_dataloader):\n",
    "            print (step)\n",
    "            print (batch)\n",
    "            break\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def train (self):\n",
    "        \n",
    "        # This training code is based on the `run_glue.py` script here:\n",
    "        # https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "        \n",
    "        # Set the seed value all over the place to make this reproducible.\n",
    "        seed_val = 42\n",
    "        random.seed (seed_val)\n",
    "        np.random.seed (seed_val)\n",
    "        torch.manual_seed (seed_val)\n",
    "        torch.cuda.manual_seed_all (seed_val)\n",
    "\n",
    "        # We'll store a number of quantities such as training and validation loss, \n",
    "        # validation accuracy, and timings.\n",
    "        training_stats = []\n",
    "        # Measure the total training time for the whole run.\n",
    "        total_t0 = time.time ()\n",
    "        # inint min_val_loss to a large val, if after each epoch eval-loss < min_val_loss, then save the model\n",
    "        min_val_loss   = 9999\n",
    "        min_train_loss = 9999\n",
    "        step = 0\n",
    "        \n",
    "        # For each epoch...\n",
    "        for epoch_i in range (0, self.epochs):\n",
    "\n",
    "            # ========================================\n",
    "            #               Training\n",
    "            # ========================================\n",
    "\n",
    "            # Perform one full pass over the training set.\n",
    "\n",
    "            print(\"\")\n",
    "            print('======== Epoch {:} / {:} ========'.format (epoch_i + 1, self.epochs))\n",
    "            print('Training...')\n",
    "\n",
    "            # Measure how long the training epoch takes.\n",
    "            t0 = time.time ()\n",
    "\n",
    "            # Reset the total loss for this epoch.\n",
    "            total_train_loss = 0\n",
    "\n",
    "            # Put the model into training mode. Don't be mislead--the call to \n",
    "            # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "            # `dropout` and `batchnorm` layers behave differently during training\n",
    "            # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "            self.model.train ()\n",
    "\n",
    "            # For each batch of training data...\n",
    "            for stp, batch in enumerate (self.train_dataloader):\n",
    "\n",
    "                step += 1\n",
    "                # Progress update every 40 batches.\n",
    "                # print ('batch =', batch)\n",
    "                if step % 50 == 0 and not step == 0:\n",
    "                    \n",
    "                    # Calculate elapsed time in minutes.\n",
    "                    elapsed = format_time (time.time() - t0)\n",
    "                    # Report progress.\n",
    "                    print ('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len (self.train_dataloader), elapsed))\n",
    "                if (self.args.max_steps > 0 and self.args.max_steps < step) or  \\\n",
    "                   (self.args.eval_steps> 0 and step % self.args.eval_steps==0 and step>0):\n",
    "                    \n",
    "                    avg_train_loss = total_train_loss / step\n",
    "                    training_time = format_time (time.time () - t0)\n",
    "                    if self.validation_dataloader:\n",
    "                        \n",
    "                        print (\"Running Validation...\")\n",
    "                        avg_val_loss, avg_val_f1, avg_val_mcc, avg_val_auc, avg_val_precision, avg_val_recall, avg_val_accuracy, validation_time = self.evaluate ()\n",
    "                        training_stats.append ({\n",
    "                                'epoch'         : epoch_i + 1,\n",
    "                                'training_loss' : avg_train_loss,\n",
    "                                'eval_loss'     : avg_val_loss,\n",
    "                                'eval_f1'       : avg_val_f1,\n",
    "                                'eval_mcc'      : avg_val_mcc, \n",
    "                                'eval_precision': avg_val_precision,\n",
    "                                'eval_recall'   : avg_val_recall,\n",
    "                                'eval_auc'      : avg_val_auc, \n",
    "                                'eval_accuracy' : avg_val_accuracy,\n",
    "                                'training_time' : training_time,\n",
    "                                'eval_time'     : validation_time                   \n",
    "                        })\n",
    "                        # save this model if the eval loss decreases from the minimum so far\n",
    "                        if avg_val_loss < min_val_loss: \n",
    "\n",
    "                            min_val_loss = avg_val_loss\n",
    "                            torch.save (model.state_dict (), \"SAKT_Rishi.pt\")     # TODO: uncomment this                    \n",
    "                self.model.zero_grad ()        \n",
    "\n",
    "                # Perform a forward pass (evaluate the model on this training batch).\n",
    "                # The documentation for this `model` function is here: \n",
    "                # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "                # It returns different numbers of parameters depending on what arguments\n",
    "                # arge given and what flags are set. For our useage here, it returns\n",
    "                # the loss (because we provided labels) and the \"logits\"--the model\n",
    "                # outputs prior to activation.\n",
    "                # loss, logits = self.model (b_inputs, .., labels=b_labels)\n",
    "                # print ('batch: \\n', batch)\n",
    "                x         = batch[0].to (device).long ()\n",
    "                target_id = batch[1].to (device).long ()\n",
    "                labels    = batch[2].to (device).long ()\n",
    "                bundle_x  = batch[3].to (device).long ()\n",
    "                tags_x    = batch[4].to (device).long ()\n",
    "                b_target  = batch[5].to (device).long ()\n",
    "                t_target  = batch[6].to (device).long ()\n",
    "                output    = self.model (x, target_id, bundle_x, tags_x, b_target, t_target, labels)\n",
    "                loss      = output.loss\n",
    "                logits    = output.logits\n",
    "                \n",
    "                # Accumulate the training loss over all of the batches so that we can\n",
    "                # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "                # single value; the `.item()` function just returns the Python value \n",
    "                # from the tensor.\n",
    "                total_train_loss += loss.item ()\n",
    "                # Perform a backward pass to calculate the gradients.\n",
    "                loss.backward ()\n",
    "\n",
    "                # Clip the norm of the gradients to 1.0.\n",
    "                # This is to help prevent the \"exploding gradients\" problem.\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
    "                # Update parameters and take a step using the computed gradient.\n",
    "                # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "                # modified based on their gradients, the learning rate, etc.\n",
    "                self.optimizer.step ()\n",
    "                # Update the learning rate.\n",
    "                self.lr_scheduler.step ()\n",
    "            # At the end of each epoch measure stats and eval:\n",
    "            # Calculate the average loss over all of the batches.\n",
    "            avg_train_loss = total_train_loss / len (self.train_dataloader)\n",
    "            # Measure how long this epoch took.\n",
    "            training_time = format_time (time.time () - t0)            \n",
    "            print (\"  Average training loss: {0:.2f}\".format (avg_train_loss))\n",
    "            print (\"  Training epcoh took: {:}\".format (training_time))\n",
    "            \n",
    "            if self.validation_dataloader:\n",
    "                \n",
    "                print (\"\\n  Running Validation...\")\n",
    "                avg_val_loss, avg_val_f1, avg_val_mcc, avg_val_auc, avg_val_precision, avg_val_recall, avg_val_accuracy, validation_time = self.evaluate ()\n",
    "                # Record all statistics from this epoch.\n",
    "                training_stats.append ({\n",
    "                        'epoch'         : epoch_i + 1,\n",
    "                        'training_loss' : avg_train_loss,\n",
    "                        'eval_loss'     : avg_val_loss,\n",
    "                        'eval_f1'       : avg_val_f1,\n",
    "                        'eval_mcc'      : avg_val_mcc, \n",
    "                        'eval_precision': avg_val_precision,\n",
    "                        'eval_recall'   : avg_val_recall,\n",
    "                        'eval_auc'      : avg_val_auc, \n",
    "                        'eval_accuracy' : avg_val_accuracy,\n",
    "                        'training_time' : training_time,\n",
    "                        'eval_time'     : validation_time                   \n",
    "                })\n",
    "                # save this epoch's model if the eval loss decreases from the minimum so far\n",
    "                if avg_val_loss < min_val_loss:\n",
    "                    \n",
    "                    min_val_loss = avg_val_loss\n",
    "                    torch.save (model.state_dict (), \"SAKT_Rishi.pt\")     # TODO: uncomment this\n",
    "            else:\n",
    "                \n",
    "                training_stats.append ({\n",
    "                    'epoch'         : epoch_i + 1,\n",
    "                    'training_loss' : avg_train_loss,\n",
    "                    'training_time' : training_time,\n",
    "                })\n",
    "                if avg_train_loss < min_train_loss: \n",
    "                    \n",
    "                    min_train_loss = avg_train_loss\n",
    "                    torch.save (model.state_dict (), \"SAKT_Rishi.pt\")     # TODO: uncomment this\n",
    "        print (\"\")\n",
    "        print (\"Training complete!\")\n",
    "        print (\"Total training took {:} (h:mm:ss)\".format (format_time (time.time ()-total_t0)))\n",
    "        self.isTrained = True\n",
    "        self.plot_train_stats (training_stats)\n",
    "        return training_stats\n",
    "    \n",
    "    def evaluate (self):\n",
    "        \n",
    "        t0 = time.time ()\n",
    "        # Put the model in evaluation mode--the dropout layers behave differently\n",
    "        # during evaluation.\n",
    "        self.model.eval ()\n",
    "\n",
    "        # Tracking variables \n",
    "        total_eval_mcc       = 0\n",
    "        total_eval_f1        = 0\n",
    "        total_eval_precision = 0\n",
    "        total_eval_recall    = 0\n",
    "        total_eval_auc       = 0\n",
    "        total_eval_accuracy  = 0\n",
    "        total_eval_loss      = 0\n",
    "        nb_eval_steps        = 0\n",
    "\n",
    "        # Evaluate data for one epoch\n",
    "        for batch in self.validation_dataloader:\n",
    "            with torch.no_grad ():\n",
    "                \n",
    "                # Forward pass, calculate logit predictions.\n",
    "                x         = batch[0].to (device).long ()\n",
    "                target_id = batch[1].to (device).long ()\n",
    "                labels    = batch[2].to (device).long ()\n",
    "                bundle_x  = batch[3].to (device).long ()\n",
    "                tags_x    = batch[4].to (device).long ()\n",
    "                b_target  = batch[5].to (device).long ()\n",
    "                t_target  = batch[6].to (device).long ()\n",
    "                output    = self.model (x, target_id, bundle_x, tags_x, b_target, t_target, labels)\n",
    "                loss      = output.loss\n",
    "                logits    = output.logits\n",
    "\n",
    "            # Accumulate the validation loss.\n",
    "            total_eval_loss += loss.item ()\n",
    "            # Move logits and labels to CPU\n",
    "            logits    = logits.detach ().cpu ().numpy ()\n",
    "            label_ids = labels.to ('cpu').numpy ()\n",
    "            label_ids = np.squeeze (label_ids.reshape ((label_ids.shape[0] * label_ids.shape[1], -1)), -1)\n",
    "\n",
    "            # Calculate the accuracy for this batch of test sentences, and\n",
    "            # accumulate it over all batches.\n",
    "            metrics = self.compute_metrics (label_ids, logits)\n",
    "            total_eval_mcc       += metrics['mcc']\n",
    "            total_eval_f1        += metrics['f1']\n",
    "            total_eval_precision += metrics['precision']\n",
    "            total_eval_recall    += metrics['recall']\n",
    "            total_eval_auc       += metrics['auc']\n",
    "            total_eval_accuracy  += metrics['accuracy']\n",
    "\n",
    "        # Report the final accuracy for this validation run.\n",
    "        avg_val_f1 = total_eval_f1 / len (self.validation_dataloader)\n",
    "        print (\"  F1: {0:.3f}\".format (avg_val_f1))\n",
    "        avg_val_mcc = total_eval_mcc / len (self.validation_dataloader)\n",
    "        print (\"  MCC: {0:.3f}\".format (avg_val_mcc))\n",
    "        avg_val_precision = total_eval_precision / len (self.validation_dataloader)\n",
    "        print (\"  Precision: {0:.3f}\".format (avg_val_precision))\n",
    "        avg_val_recall = total_eval_recall / len (self.validation_dataloader)\n",
    "        print (\"  Recall: {0:.3f}\".format (avg_val_recall))\n",
    "        avg_val_auc = total_eval_auc / len (self.validation_dataloader)\n",
    "        print (\"  AUC: {0:.3f}\".format (avg_val_auc))\n",
    "        avg_val_accuracy = total_eval_accuracy / len (self.validation_dataloader)\n",
    "        print (\"  Accuracy: {0:.3f}\".format (avg_val_accuracy))\n",
    "        # Calculate the average loss over all of the batches.\n",
    "        avg_val_loss = total_eval_loss / len (self.validation_dataloader)\n",
    "        # Measure how long the validation run took.\n",
    "        validation_time = format_time (time.time () - t0)\n",
    "        print (\"  Validation Loss: {0:.2f}\".format (avg_val_loss))\n",
    "        print (\"  Validation took: {:}\".format (validation_time))            \n",
    "        return avg_val_loss, avg_val_f1, avg_val_mcc, avg_val_auc, avg_val_precision, avg_val_recall, avg_val_accuracy, validation_time\n",
    "    \n",
    "    def plot_train_stats (self, training_stats):\n",
    "        \"\"\"\n",
    "        Draw Classification Report curve\n",
    "        \"\"\"\n",
    "        \n",
    "        mccs   = accuracies = f1_scores = precisions = recalls = auc = losses = epochs = -1\n",
    "        epochs = training_stats[-1]['epoch']\n",
    "        if 'eval_mcc' in training_stats[0]:\n",
    "            mccs       = [e['eval_mcc'] for e in training_stats]\n",
    "            sns.lineplot (x=np.arange(1, epochs + 1), y=mccs,       label='val_mcc')\n",
    "        if 'eval_accuracy' in training_stats[0]:\n",
    "            accuracies = [e['eval_accuracy'] for e in training_stats]\n",
    "            sns.lineplot (x=np.arange(1, epochs + 1), y=accuracies, label='val_accuracy')\n",
    "        if 'eval_f1' in training_stats[0]:\n",
    "            f1_scores  = [e['eval_f1'] for e in training_stats]\n",
    "            sns.lineplot (x=np.arange(1, epochs + 1), y=f1_scores,  label='val_f1') \n",
    "        if 'eval_precision' in training_stats[0]:\n",
    "            precisions = [e['eval_precision'] for e in training_stats]\n",
    "            sns.lineplot (x=np.arange(1, epochs + 1), y=precisions, label='val_precision')\n",
    "        if 'eval_recall' in training_stats[0]:\n",
    "            recalls    = [e['eval_recall'] for e in training_stats]\n",
    "            sns.lineplot (x=np.arange(1, epochs + 1), y=recalls,    label='val_recall')\n",
    "        if 'eval_auc' in training_stats[0]:\n",
    "            auc        = [e['eval_auc'] for e in training_stats]\n",
    "            sns.lineplot (x=np.arange(1, epochs + 1), y=mccs,       label='val_auc')\n",
    "        if 'eval_loss' in training_stats[0]:\n",
    "            losses     = [e['eval_loss'] for e in training_stats]\n",
    "        if 'training_loss'  in training_stats[0]:\n",
    "            tr_losses  = [e['training_loss'] for e in training_stats]\n",
    "            sns.lineplot (x=np.arange(1, epochs + 1), y=tr_losses,  label='tr_losses')\n",
    "            \n",
    "        plt.show ()\n",
    "        print ('mccs       :', mccs)\n",
    "        print ('accuracies :', accuracies)\n",
    "        print ('precisions :', precisions)\n",
    "        print ('recalls    :', recalls)\n",
    "        print ('f1_scores  :', f1_scores)\n",
    "        print ('auc        :', auc)\n",
    "        print ('losses     :', losses)\n",
    "        print ('tr_losses  :', tr_losses)\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def getTrainedModel (self):\n",
    "        \n",
    "        if self.isTrained:\n",
    "            return self.model\n",
    "        return None\n",
    "    \n",
    "    \n",
    "    def predict (self, prediction_dataset, isRemoveLabels=True):\n",
    "        \"\"\"\n",
    "        return: pred_logits, true_labels, metrics (if true 'labels' are input in the prediction_dataset)\n",
    "        \"\"\"     \n",
    "        \n",
    "        prediction_sampler    = SequentialSampler (prediction_dataset)\n",
    "        prediction_dataloader = DataLoader (prediction_dataset, sampler=prediction_sampler, batch_size=self.args.per_device_eval_batch_size)\n",
    "        print ('Predicting labels for {:,} test sentences...'.format (len (prediction_dataset)))\n",
    "        \n",
    "        # Put model in evaluation mode\n",
    "        self.model.eval ()\n",
    "\n",
    "        # Tracking variables \n",
    "        predictions = []\n",
    "        # true_labels = []\n",
    "        \n",
    "        # Predict \n",
    "        for batch in prediction_dataloader:\n",
    "            \n",
    "            # Add batch to GPU\n",
    "            batch = {t:batch[t].to (self.device) for t in batch}\n",
    "\n",
    "            # Unpack the inputs from our dataloader\n",
    "            # b_input_ids, b_input_mask, b_segment_ids = batch\n",
    "\n",
    "            # Telling the model not to compute or store gradients, saving memory and \n",
    "            # speeding up prediction\n",
    "            with torch.no_grad ():\n",
    "                # Forward pass, calculate logit predictions\n",
    "                if isRemoveLabels:\n",
    "                    batch.pop ('labels')\n",
    "                for k in batch:\n",
    "                    batch[k] = batch[k].to (self.device)\n",
    "                outputs = model (**batch)\n",
    "            logits = outputs[0]\n",
    "\n",
    "            # Move logits and labels to CPU\n",
    "            logits = logits.detach ().cpu ().numpy ()\n",
    "            # label_ids = b_labels.to ('cpu').numpy ()\n",
    "\n",
    "            # Store predictions and true labels\n",
    "            predictions.append (logits)\n",
    "            # true_labels.append (label_ids)\n",
    "            print ('Done predictions for ', len(predictions), '/', len(prediction_dataloader), 'batches')\n",
    "        print ('Done prediction')\n",
    "        \n",
    "        # Combine the results across all batches to get the predicted logits\n",
    "        pred_logits = np.concatenate (predictions, axis=0)\n",
    "        # For each sample, pick the label (0,1,2) with the highest score.\n",
    "        # pred_labels = np.argmax (pred_logits, axis=1).flatten()\n",
    "        # returns the predicted logits\n",
    "        return pred_logits, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T14:40:55.486245Z",
     "iopub.status.busy": "2021-01-10T14:40:55.485562Z",
     "iopub.status.idle": "2021-01-10T14:41:03.000467Z",
     "shell.execute_reply": "2021-01-10T14:41:02.999981Z"
    },
    "papermill": {
     "duration": 7.565188,
     "end_time": "2021-01-10T14:41:03.000598",
     "exception": false,
     "start_time": "2021-01-10T14:40:55.435410",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SAKTModel(\n",
       "  (embedding): Embedding(27047, 128)\n",
       "  (pos_embedding): Embedding(255, 128)\n",
       "  (e_embedding): Embedding(13524, 128)\n",
       "  (bundle_embedding): Embedding(13523, 128)\n",
       "  (tag_embedding): Embedding(188, 128)\n",
       "  (multi_att): MultiheadAttention(\n",
       "    (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (layer_normal): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  (ffn): FFN(\n",
       "    (lr1): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (lr2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (outDense): Linear(in_features=128, out_features=2, bias=True)\n",
       "  (outActivtn): LogSoftmax(dim=1)\n",
       "  (NLLLoss): NLLLoss()\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = SAKTModel (n_skill, embed_dim=128)\n",
    "try:\n",
    "    model.load_state_dict (torch.load (\"../input/rishi-sakt-featureembeddings-riidchallenge/SAKT_Rishi.pt\"))\n",
    "except:\n",
    "    model.load_state_dict (torch.load (\"../input/rishi-sakt-featureembeddings-riidchallenge/SAKT_Rishi.pt\", map_location='cpu'))\n",
    "\n",
    "model.to (device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T14:41:03.084941Z",
     "iopub.status.busy": "2021-01-10T14:41:03.084091Z",
     "iopub.status.idle": "2021-01-10T14:41:03.088202Z",
     "shell.execute_reply": "2021-01-10T14:41:03.088742Z"
    },
    "papermill": {
     "duration": 0.05009,
     "end_time": "2021-01-10T14:41:03.088865",
     "exception": false,
     "start_time": "2021-01-10T14:41:03.038775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments (\n",
    "\n",
    "    output_dir      = './results',     # output directory\n",
    "    num_train_epochs= 1,               # Actually = 13 for training from scratch, without using the SAKT_Rishi.pt\n",
    "    warmup_steps    = 1000,            # for lr scheduling\n",
    "    eval_steps      = 500,             # Number of update steps between two evaluations, if <=0 then eval at end of each epoch\n",
    "    max_steps       = 0,               # If set to a positive number, the total number of training steps to perform. Overrides num_train_epochs\n",
    "    learning_rate   = 1e-6,            # Actually = 1e-2 for training from scratch, without using the SAKT_Rishi.pt\n",
    "    # adam_epsilon  = 1e-8             # - default is 1e-8 is â€œa very small number to prevent any division by zero\"\n",
    "    per_device_train_batch_size= 1024, # batch size per device during training\n",
    "    per_device_eval_batch_size = 1024, # batch size for evaluation\n",
    ")\n",
    "\n",
    "trainer = MyTrainer (\n",
    "    \n",
    "    model         = model,           # the instantiated ðŸ¤— Transformers model to be trained\n",
    "    args          = training_args,   # training arguments, defined above\n",
    "    train_dataset = train_dataset,   # training dataset\n",
    "    eval_dataset  = eval_dataset,    # evaluation dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T14:41:03.170757Z",
     "iopub.status.busy": "2021-01-10T14:41:03.170116Z",
     "iopub.status.idle": "2021-01-10T15:15:21.761815Z",
     "shell.execute_reply": "2021-01-10T15:15:21.759502Z"
    },
    "papermill": {
     "duration": 2058.634945,
     "end_time": "2021-01-10T15:15:21.761947",
     "exception": false,
     "start_time": "2021-01-10T14:41:03.127002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 1 ========\n",
      "Training...\n",
      "  Batch    50  of    366.    Elapsed: 0:04:59.\n",
      "  Batch   100  of    366.    Elapsed: 0:09:17.\n",
      "  Batch   150  of    366.    Elapsed: 0:13:39.\n",
      "  Batch   200  of    366.    Elapsed: 0:18:01.\n",
      "  Batch   250  of    366.    Elapsed: 0:22:59.\n",
      "  Batch   300  of    366.    Elapsed: 0:27:14.\n",
      "  Batch   350  of    366.    Elapsed: 0:31:25.\n",
      "  Average training loss: 0.15\n",
      "  Training epcoh took: 0:32:25\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.872\n",
      "  MCC: 0.747\n",
      "  Precision: 0.856\n",
      "  Recall: 0.892\n",
      "  AUC: 0.971\n",
      "  Accuracy: 0.920\n",
      "  Validation Loss: 0.16\n",
      "  Validation took: 0:01:53\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:34:18 (h:mm:ss)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mccs       : [0.7473622259206276]\n",
      "accuracies : [0.920264284620098]\n",
      "precisions : [0.8558711098410392]\n",
      "recalls    : [0.8923829491426781]\n",
      "f1_scores  : [0.872367097344225]\n",
      "auc        : [0.9706462821585478]\n",
      "losses     : [0.15635967627167702]\n",
      "tr_losses  : [0.15495783416299871]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'epoch': 1,\n",
       "  'training_loss': 0.15495783416299871,\n",
       "  'eval_loss': 0.15635967627167702,\n",
       "  'eval_f1': 0.872367097344225,\n",
       "  'eval_mcc': 0.7473622259206276,\n",
       "  'eval_precision': 0.8558711098410392,\n",
       "  'eval_recall': 0.8923829491426781,\n",
       "  'eval_auc': 0.9706462821585478,\n",
       "  'eval_accuracy': 0.920264284620098,\n",
       "  'training_time': '0:32:25',\n",
       "  'eval_time': '0:01:53'}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T15:15:21.870298Z",
     "iopub.status.busy": "2021-01-10T15:15:21.869402Z",
     "iopub.status.idle": "2021-01-10T15:15:21.874824Z",
     "shell.execute_reply": "2021-01-10T15:15:21.874034Z"
    },
    "papermill": {
     "duration": 0.063138,
     "end_time": "2021-01-10T15:15:21.874963",
     "exception": false,
     "start_time": "2021-01-10T15:15:21.811825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments (\n",
    "\n",
    "    output_dir       = './results',     # output directory\n",
    "    num_train_epochs = 1,               # total # of training epochs\n",
    "    warmup_steps     = 100,             # for lr scheduling\n",
    "    eval_steps       = 300,             # Number of update steps between two evaluations, if <=0 then eval at end of each epoch\n",
    "    max_steps        = 0,               # If set to a positive number, the total number of training steps to perform. Overrides num_train_epochs\n",
    "    learning_rate    = 1e-7,            # Actually = 1e-4 for training from scratch, without using the SAKT_Rishi.pt\n",
    "    # adam_epsilon=1e-8                 # - default is 1e-8 is â€œa very small number to prevent any division by zero\"\n",
    "    per_device_train_batch_size = 1024, # batch size per device during training\n",
    "    per_device_eval_batch_size  = 1024, # batch size for evaluation\n",
    ")\n",
    "\n",
    "trainer = MyTrainer (\n",
    "    \n",
    "    model         = model,          # the instantiated ðŸ¤— Transformers model to be trained\n",
    "    args          = training_args,  # training arguments, defined above\n",
    "    train_dataset = eval_dataset,  # training dataset\n",
    "    eval_dataset  = None,           # evaluation dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T15:15:21.972016Z",
     "iopub.status.busy": "2021-01-10T15:15:21.971000Z",
     "iopub.status.idle": "2021-01-10T15:17:08.021947Z",
     "shell.execute_reply": "2021-01-10T15:17:08.021304Z"
    },
    "papermill": {
     "duration": 106.100773,
     "end_time": "2021-01-10T15:17:08.022060",
     "exception": false,
     "start_time": "2021-01-10T15:15:21.921287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 1 ========\n",
      "Training...\n",
      "  Average training loss: 0.16\n",
      "  Training epcoh took: 0:01:46\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:01:46 (h:mm:ss)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mccs       : -1\n",
      "accuracies : -1\n",
      "precisions : -1\n",
      "recalls    : -1\n",
      "f1_scores  : -1\n",
      "auc        : -1\n",
      "losses     : -1\n",
      "tr_losses  : [0.15724073871970176]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'epoch': 1,\n",
       "  'training_loss': 0.15724073871970176,\n",
       "  'training_time': '0:01:46'}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T15:17:08.129725Z",
     "iopub.status.busy": "2021-01-10T15:17:08.128877Z",
     "iopub.status.idle": "2021-01-10T15:17:08.423371Z",
     "shell.execute_reply": "2021-01-10T15:17:08.424102Z"
    },
    "papermill": {
     "duration": 0.351444,
     "end_time": "2021-01-10T15:17:08.424285",
     "exception": false,
     "start_time": "2021-01-10T15:17:08.072841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len (group) = 393656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "user_id\n",
       "2058553426    ([7900, 7876, 175, 1278, 2064, 2065, 2063, 336...\n",
       "1658799651    ([7900, 7876, 175, 1278, 2065, 2064, 2063, 336...\n",
       "564422495     ([7900, 7876, 175, 1278, 2065, 2063, 2064, 336...\n",
       "1744078086    ([3560, 8275, 98, 6374, 5070, 5651, 5338, 5673...\n",
       "1980281378    ([7900, 7876, 175, 1278, 2064, 2063, 2065, 336...\n",
       "                                    ...                        \n",
       "1651844166    ([7900, 7876, 175, 1278, 2064, 2063, 2065, 336...\n",
       "985472128     ([6169, 4325, 7976, 5235, 6678, 5608, 3887, 49...\n",
       "248149795     ([8277, 6347, 325, 5163, 4764, 4009, 6400, 356...\n",
       "1706290279    ([3919, 1112, 296, 376, 5976, 5183, 5170, 5849...\n",
       "1746968974    ([5197, 4290, 4620, 3550, 488, 7951, 3928, 789...\n",
       "Length: 393656, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group = train_group.append (eval_group)\n",
    "print ('len (group) =', len (group))\n",
    "del train_group, eval_group, train_dataset, eval_dataset, training_args, trainer\n",
    "gc.collect ()\n",
    "group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.047674,
     "end_time": "2021-01-10T15:17:08.521074",
     "exception": false,
     "start_time": "2021-01-10T15:17:08.473400",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# get test SAKT Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T15:17:08.643016Z",
     "iopub.status.busy": "2021-01-10T15:17:08.641258Z",
     "iopub.status.idle": "2021-01-10T15:17:08.644051Z",
     "shell.execute_reply": "2021-01-10T15:17:08.644535Z"
    },
    "papermill": {
     "duration": 0.07545,
     "end_time": "2021-01-10T15:17:08.644670",
     "exception": false,
     "start_time": "2021-01-10T15:17:08.569220",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TestDataset (Dataset):\n",
    "    \n",
    "    def __init__(self, samples, test_df, skills, max_seq=MAX_SEQ):\n",
    "        \n",
    "        super (TestDataset, self).__init__()\n",
    "        self.samples  = samples\n",
    "        self.user_ids = [x for x in test_df[\"user_id\"].unique()]\n",
    "        self.test_df  = test_df\n",
    "        self.skills   = skills\n",
    "        self.n_skill  = max (skills) + 1\n",
    "        self.max_seq  = max_seq\n",
    "        return\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.test_df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        test_info     = self.test_df.iloc[index]\n",
    "        user_id       = test_info[\"user_id\"]\n",
    "        target_id     = test_info[\"content_id\"]\n",
    "        target_tags   = test_info[\"tags\"]\n",
    "        target_bundle = test_info[\"bundle_id\"]\n",
    "        if target_id not in known_qtn_ids:\n",
    "            target_id = 0\n",
    "        if target_bundle not in known_bundle_ids:            \n",
    "            target_bundle = 0\n",
    "        for i in range (len (target_tags)):\n",
    "            if target_tags[i] not in known_tags:                \n",
    "                target_tags[i] = 0\n",
    "        q  = np.zeros (self.max_seq, dtype=int)\n",
    "        qa = np.zeros (self.max_seq, dtype=int)\n",
    "        b  = np.zeros (self.max_seq, dtype=int)\n",
    "        t  = np.array ([[0]*5]*self.max_seq, dtype=int)  # a question can have upto say 5 tags\n",
    "        if user_id in self.samples.index:\n",
    "            \n",
    "            # q_, qa_, b_, t_ = self.samples[user_id]\n",
    "            q_, qa_ = self.samples[user_id]\n",
    "            q_b_t_df = pd.DataFrame.from_dict ({'question_id': q_})\n",
    "            q_b_t_df = q_b_t_df.merge (questions_df, on='question_id', how='left')\n",
    "            b_       = q_b_t_df.bundle_id.values\n",
    "            t_       = np.vstack (q_b_t_df.tags.values)\n",
    "            del q_b_t_df\n",
    "            seq_len = len (q_)            \n",
    "            if seq_len >= self.max_seq:\n",
    "                \n",
    "                q  = q_[-self.max_seq:]\n",
    "                qa = qa_[-self.max_seq:]\n",
    "                b  = b_[-self.max_seq:]\n",
    "                t  = t_[-self.max_seq:]\n",
    "            else:\n",
    "                \n",
    "                q[-seq_len:]  = q_\n",
    "                qa[-seq_len:] = qa_\n",
    "                b[-seq_len:]  = b_\n",
    "                t[-seq_len:]  = t_\n",
    "        \n",
    "        x = np.zeros (self.max_seq-1, dtype=int)\n",
    "        x = q[1:].copy ()\n",
    "        x += (qa[1:] == 1) * self.n_skill\n",
    "        \n",
    "        questions = np.append (q[2:], [target_id]) # just [target_id] should do, no need of a sequence of max_seq_len for query Qn_id\n",
    "        bundle_x  = b[1:].copy ()\n",
    "        tags_x    = t[1:].copy ()\n",
    "        b_target  = np.append (b[2:], [target_bundle])\n",
    "        t_target  = np.vstack ((t[2:], target_tags))\n",
    "        \n",
    "        return x, questions, bundle_x, tags_x, b_target, t_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.048034,
     "end_time": "2021-01-10T15:17:08.743371",
     "exception": false,
     "start_time": "2021-01-10T15:17:08.695337",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "test_dataset = TestDataset (group, train_df, train_df[\"content_id\"])\n",
    "item = test_dataset.__getitem__(5)\n",
    "print (item[0].shape, item[1].shape, item[2].shape, item[3].shape, item[4].shape, item[5].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.046259,
     "end_time": "2021-01-10T15:17:08.836654",
     "exception": false,
     "start_time": "2021-01-10T15:17:08.790395",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "for item in DataLoader (test_dataset):\n",
    "    print (item[0].shape, item[1].shape, item[2].shape, item[3].shape, item[4].shape, item[5].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T15:17:08.944418Z",
     "iopub.status.busy": "2021-01-10T15:17:08.941574Z",
     "iopub.status.idle": "2021-01-10T15:17:08.968426Z",
     "shell.execute_reply": "2021-01-10T15:17:08.967392Z"
    },
    "papermill": {
     "duration": 0.085496,
     "end_time": "2021-01-10T15:17:08.968604",
     "exception": false,
     "start_time": "2021-01-10T15:17:08.883108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import riiideducation\n",
    "\n",
    "env       = riiideducation.make_env ()\n",
    "iter_test = env.iter_test ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T15:17:09.081952Z",
     "iopub.status.busy": "2021-01-10T15:17:09.076769Z",
     "iopub.status.idle": "2021-01-10T15:17:10.803755Z",
     "shell.execute_reply": "2021-01-10T15:17:10.804515Z"
    },
    "papermill": {
     "duration": 1.784147,
     "end_time": "2021-01-10T15:17:10.804758",
     "exception": false,
     "start_time": "2021-01-10T15:17:09.020611",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.10it/s]\n",
      "1it [00:00,  3.50it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.50it/s]\n",
      "2it [00:00,  3.17it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.84it/s]\n",
      "3it [00:00,  3.20it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.58it/s]\n",
      "4it [00:01,  2.35it/s]\n"
     ]
    }
   ],
   "source": [
    "model.eval ()\n",
    "prev_test_df = None\n",
    "for (test_df, sample_prediction_df) in tqdm (iter_test):\n",
    "    \n",
    "    # test_df = test_df[test_df.content_type_id == False]\n",
    "    test_df = test_df.merge (questions_df, left_on='content_id', right_on='question_id', how='left').drop (columns=['question_id'])\n",
    "    if (prev_test_df is not None) & (psutil.virtual_memory ().percent<90):\n",
    "        \n",
    "        print (psutil.virtual_memory ().percent)\n",
    "        prev_test_df['answered_correctly'] = eval (test_df['prior_group_answers_correct'].iloc[0])\n",
    "        prev_test_df = prev_test_df[prev_test_df.content_type_id == False]\n",
    "        prev_group = prev_test_df[['user_id', 'content_id', 'answered_correctly', 'bundle_id', 'tags']].groupby ('user_id').apply (lambda r: (\n",
    "            r['content_id'].values,\n",
    "            r['answered_correctly'].values,\n",
    "            r['bundle_id'].values,\n",
    "            np.vstack (list(r['tags'].values))))\n",
    "        for prev_user_id in prev_group.index:\n",
    "            \n",
    "            prev_group_content = prev_group[prev_user_id][0]\n",
    "            prev_group_ac      = prev_group[prev_user_id][1]\n",
    "            prev_group_bund_id = prev_group[prev_user_id][2]\n",
    "            prev_group_tags    = prev_group[prev_user_id][3]\n",
    "            if prev_user_id in group.index:\n",
    "                \n",
    "                group[prev_user_id] = (np.append(group[prev_user_id][0],  prev_group_content), \n",
    "                                       np.append(group[prev_user_id][1],  prev_group_ac))\n",
    "            else:\n",
    "                group[prev_user_id] = (prev_group_content, prev_group_ac)\n",
    "            if len (group[prev_user_id][0]) > MAX_SEQ:\n",
    "                \n",
    "                new_group_content   = group[prev_user_id][0][-MAX_SEQ:]\n",
    "                new_group_ac        = group[prev_user_id][1][-MAX_SEQ:]\n",
    "                group[prev_user_id] = (new_group_content, new_group_ac)\n",
    "    prev_test_df    = test_df.copy ()    \n",
    "    test_df         = test_df[test_df.content_type_id == False]                \n",
    "    test_dataset    = TestDataset (group, test_df, skills)\n",
    "    test_dataloader = DataLoader (test_dataset, batch_size=1024, shuffle=False)  # TODO: uncomment this\n",
    "    outs            = []\n",
    "    softmax         = nn.Softmax (dim=1)\n",
    "    for item in tqdm (test_dataloader):\n",
    "        \n",
    "        # item = (x, questions, bundle_x, tags_x, b_target, t_target)\n",
    "        x         = item[0].to (device).long ()\n",
    "        target_id = item[1].to (device).long ()\n",
    "        bundle_x  = item[2].to (device).long ()\n",
    "        tags_x    = item[3].to (device).long ()\n",
    "        b_target  = item[4].to (device).long ()\n",
    "        t_target  = item[5].to (device).long ()\n",
    "        \n",
    "        with torch.no_grad ():\n",
    "            pred_logits = model (x, target_id, bundle_x, tags_x, b_target, t_target)  # returns a named tuple\n",
    "        pred_logits = pred_logits.logits.cpu ()\n",
    "        pred_pr     = softmax (pred_logits).numpy ()\n",
    "        pred_pr     = pred_pr[:, 1]   # return the prob of binary class=1\n",
    "        \n",
    "        # pred = (output >= 0.5).long()\n",
    "        # loss = criterion(output, label)\n",
    "        # val_loss.append(loss.item())\n",
    "        # num_corrects += (pred == label).sum().item()\n",
    "        # num_total += len(label)\n",
    "        # labels.extend(label.squeeze(-1).data.cpu().numpy())\n",
    "        outs.extend (pred_pr)\n",
    "        \n",
    "    test_df['answered_correctly'] =  outs\n",
    "    env.predict (test_df.loc[test_df['content_type_id'] == 0, ['row_id', 'answered_correctly']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T15:17:10.936141Z",
     "iopub.status.busy": "2021-01-10T15:17:10.935271Z",
     "iopub.status.idle": "2021-01-10T15:17:10.939655Z",
     "shell.execute_reply": "2021-01-10T15:17:10.940341Z"
    },
    "papermill": {
     "duration": 0.072026,
     "end_time": "2021-01-10T15:17:10.940505",
     "exception": false,
     "start_time": "2021-01-10T15:17:10.868479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done !\n"
     ]
    }
   ],
   "source": [
    "print (\"Done !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.062353,
     "end_time": "2021-01-10T15:17:11.065432",
     "exception": false,
     "start_time": "2021-01-10T15:17:11.003079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "papermill": {
   "duration": 2786.929475,
   "end_time": "2021-01-10T15:17:12.274010",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-01-10T14:30:45.344535",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
